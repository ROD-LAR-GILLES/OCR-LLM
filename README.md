# OCR-LLM: Procesamiento de Documentos con OCR y LLM

Sistema de procesamiento de documentos PDF que combina OCR avanzado usando Donut (Document Understanding Transformer) con LLM (Modelos de Lenguaje Grande) para extraer y mejorar texto de documentos escaneados.

## üöÄ Caracter√≠sticas

- **OCR Avanzado con Donut**: Extracci√≥n de texto estructurado sin dependencia de Tesseract
- **Reconocimiento de Estructura**: Detecta p√°rrafos, tablas y encabezados
- **Procesamiento en Lotes**: Maneja m√∫ltiples documentos eficientemente
- **Mejora con LLM**: Refina y estructura el texto extra√≠do
- **Flexible**: Soporta m√∫ltiples motores OCR (Donut, Tesseract, DocTR)

## üõ†Ô∏è Motores OCR Disponibles

1. **Donut** (Predeterminado)
   - Basado en transformers
   - Reconocimiento de estructura
   - Mejor calidad en documentos complejos

2. **Tesseract** (Fallback)
   - Motor OCR tradicional
   - R√°pido y ligero
   - Bueno para textos simples

3. **DocTR** (Alternativa Ligera)
   - M√°s r√°pido en CPU
   - Menor uso de memoria
   - Buena precisi√≥n general

## Arquitectura

El proyecto sigue una arquitectura hexagonal (puertos y adaptadores):

```
src/
‚îú‚îÄ‚îÄ config/        # Configuraci√≥n y DI
‚îú‚îÄ‚îÄ domain/        # L√≥gica de negocio
‚îú‚îÄ‚îÄ infrastructure/# Adaptadores
‚îî‚îÄ‚îÄ interfaces/    # CLI y API
```

## Roadmap

### Sprint 1: Mejoras en el Procesamiento Core

#### 1.1 Procesamiento Paralelo
- [ ] Implementaci√≥n de ProcessingService con soporte multithread
  ```python
  class ProcessingService:
      def process_batch(self, documents: List[Document], workers: int = 3)
      def process_async(self, document: Document) -> Future[Document]
  ```
- [ ] Cola de procesamiento con prioridades
- [ ] Sistema robusto de manejo de errores

#### 1.2 Mejoras OCR
- [ ] Preprocesamiento de im√°genes
  - Detecci√≥n autom√°tica de orientaci√≥n
  - Correcci√≥n de sesgo
  - Mejora de contraste
- [ ] Detecci√≥n inteligente de layouts
  - Reconocimiento de columnas
  - Identificaci√≥n de tablas
  - Extracci√≥n de headers/footers
- [ ] Soporte multilenguaje
  - Detecci√≥n autom√°tica de idioma
  - Diccionarios espec√≠ficos por dominio

#### 1.3 Optimizaciones LLM
- [ ] Sistema de cach√©
  ```python
  class LlmCache:
      def get_cached_response(self, text_hash: str) -> Optional[str]
      def cache_response(self, text_hash: str, response: str)
  ```
- [ ] Prompts especializados por tipo de documento
- [ ] Sistema de fallback y reintentos

### Sprint 2: API y Almacenamiento

#### 2.1 API REST (FastAPI)
- [ ] Endpoints CRUD
  ```bash
  POST   /api/v1/documents      # Subir documento
  GET    /api/v1/documents      # Listar documentos
  GET    /api/v1/documents/{id} # Obtener documento
  DELETE /api/v1/documents/{id} # Eliminar documento
  ```
- [ ] Autenticaci√≥n y autorizaci√≥n
- [ ] Documentaci√≥n OpenAPI

#### 2.2 Sistema de Almacenamiento
- [ ] Soporte para S3
  ```python
  class S3Storage(StoragePort):
      def save_document(self, doc: Document) -> str
      def load_document(self, path: str) -> Document
  ```
- [ ] Versionado de documentos
- [ ] Gesti√≥n de cach√©

#### 2.3 Monitoreo
- [ ] Logging estructurado
- [ ] M√©tricas de rendimiento
- [ ] Sistema de alertas

### Sprint 3: Testing y CI/CD

#### 3.1 Testing Exhaustivo
- [ ] Tests de integraci√≥n
  ```python
  def test_end_to_end_processing():
      # Probar flujo completo
  
  def test_error_handling():
      # Verificar manejo de errores
  ```
- [ ] Tests de rendimiento
- [ ] Mocks para servicios externos

#### 3.2 Pipeline CI/CD
- [ ] GitHub Actions
  ```yaml
  name: CI/CD Pipeline
  on: [push, pull_request]
  jobs:
    test:
      # Tests automatizados
    lint:
      # An√°lisis de c√≥digo
    deploy:
      # Despliegue autom√°tico
  ```
- [ ] An√°lisis est√°tico
- [ ] Despliegue autom√°tico

#### 3.3 Documentaci√≥n
- [ ] API Reference
- [ ] Gu√≠as de uso
- [ ] Ejemplos pr√°cticos

## M√©tricas de √âxito

1. **Rendimiento**
   - Tiempo de procesamiento < 30s por p√°gina
   - Precisi√≥n OCR > 95%
   - Latencia API < 100ms

2. **Calidad**
   - Cobertura de tests > 80%
   - Zero vulnerabilidades cr√≠ticas
   - Documentaci√≥n actualizada

## Configuraci√≥n del Entorno

```bash
# Instalar dependencias
pip install -e ".[dev]"

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Ejecutar tests
pytest tests/
```

## Contribuci√≥n

1. Fork el repositorio
2. Crea una rama para tu feature
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. Commit tus cambios
   ```bash
   git commit -m "feat(amazing): add something amazing"
   ```
4. Push a la rama
   ```bash
   git push origin feature/amazing-feature
   ```
5. Abre un Pull Request

## Convenciones

- **Commits**: Seguimos [Conventional Commits](https://www.conventionalcommits.org/)
- **C√≥digo**: [Black](https://github.com/psf/black) para formateo
- **Documentaci√≥n**: Docstrings en Google style
- **Testing**: Pytest para todos los tests

## Licencia

Este proyecto est√° licenciado bajo MIT License - ver el archivo [LICENSE](LICENSE) para detalles.

## Agradecimientos

- OpenAI por la API GPT
- Tesseract OCR
- La comunidad de c√≥digo abierto

---

No olvides dar una estrella si encuentras √∫til este proyecto!
