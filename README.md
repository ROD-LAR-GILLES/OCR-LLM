# OCR-LLM

Sistema de OCR basado en el modelo Donut con procesamiento as√≠ncrono y API REST.

[![CI/CD](https://github.com/ROD-LAR-GILLES/OCR-LLM/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/ROD-LAR-GILLES/OCR-LLM/actions/workflows/ci-cd.yml)
[![Coverage](https://codecov.io/gh/ROD-LAR-GILLES/OCR-LLM/branch/main/graph/badge.svg)](https://codecov.io/gh/ROD-LAR-GILLES/OCR-LLM)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Caracter√≠sticas

- üîç OCR de alta precisi√≥n usando el modelo Donut
- üöÄ Procesamiento as√≠ncrono de documentos
- üìä API REST con FastAPI
- üíæ Sistema de cach√© con Redis
- üìà Monitoreo y m√©tricas con Prometheus
- üîÑ Soporte para procesamiento por lotes

## Inicio R√°pido

### Instalaci√≥n

```bash
# Clonar el repositorio
git clone https://github.com/ROD-LAR-GILLES/OCR-LLM.git
cd OCR-LLM

# Crear un entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -e ".[dev]"
```

### Uso B√°sico

```python
from ocr_llm.application.document_service import DocumentService

# Procesar un documento
document = await document_service.process_one("documento.pdf")
print(document.text)

# Procesar m√∫ltiples documentos
documents = await document_service.process_batch(["doc1.pdf", "doc2.pdf"])
```

### Uso de la API

```bash
# Iniciar la API
uvicorn src.interfaces.api.app:app --reload

# Procesar un documento v√≠a API
curl -X POST http://localhost:8000/api/v1/documents \
  -F "file=@documento.pdf" \
  -F "quality=90"
```

## Documentaci√≥n

- [Gu√≠a de Instalaci√≥n](docs/installation.md)
- [Documentaci√≥n de la API](docs/api.md)
- [Gu√≠a de Desarrollo](docs/development.md)
- [Arquitectura](docs/architecture.md)

## Desarrollo

### Configuraci√≥n del Entorno

```bash
# Instalar dependencias de desarrollo
pip install -e ".[dev]"

# Ejecutar pruebas
pytest

# Verificar formato
black src tests
isort src tests

# Verificar tipos
mypy src tests
```

### Docker

```bash
# Construir imagen
docker build -t ocr-llm .

# Ejecutar
docker run -p 8000:8000 ocr-llm
```

## Monitoreo

El proyecto incluye endpoints de monitoreo:

- `/metrics` - M√©tricas Prometheus
- `/health` - Estado del servicio
- `/docs` - Documentaci√≥n OpenAPI

## Contribuir

¬°Las contribuciones son bienvenidas! Por favor, lee nuestra [Gu√≠a de Contribuci√≥n](CONTRIBUTING.md).

## Licencia

Este proyecto est√° licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.: Procesamiento de Documentos con OCR y LLM

Sistema de procesamiento de documentos PDF que combina OCR avanzado usando Donut (Document Understanding Transformer) con LLM (Modelos de Lenguaje Grande) para extraer y mejorar texto de documentos escaneados.

## üöÄ Caracter√≠sticas

- **OCR Avanzado con Donut**: Extracci√≥n de texto estructurado sin dependencia de Tesseract
- **Reconocimiento de Estructura**: Detecta p√°rrafos, tablas y encabezados
- **Procesamiento en Lotes**: Maneja m√∫ltiples documentos eficientemente
- **Mejora con LLM**: Refina y estructura el texto extra√≠do
- **Flexible**: Soporta m√∫ltiples motores OCR (Donut, Tesseract, DocTR)

## üõ†Ô∏è Motores OCR Disponibles

1. **Donut** (Predeterminado)
   - Basado en transformers
   - Reconocimiento de estructura
   - Mejor calidad en documentos complejos

2. **Tesseract** (Fallback)
   - Motor OCR tradicional
   - R√°pido y ligero
   - Bueno para textos simples

3. **DocTR** (Alternativa Ligera)
   - M√°s r√°pido en CPU
   - Menor uso de memoria
   - Buena precisi√≥n general

## Arquitectura

El proyecto sigue una arquitectura hexagonal (puertos y adaptadores):

```
src/
‚îú‚îÄ‚îÄ config/        # Configuraci√≥n y DI
‚îú‚îÄ‚îÄ domain/        # L√≥gica de negocio
‚îú‚îÄ‚îÄ infrastructure/# Adaptadores
‚îî‚îÄ‚îÄ interfaces/    # CLI y API
```

## Roadmap

### Sprint 1: Mejoras en el Procesamiento Core

#### 1.1 Procesamiento Paralelo
- [ ] Implementaci√≥n de ProcessingService con soporte multithread
  ```python
  class ProcessingService:
      def process_batch(self, documents: List[Document], workers: int = 3)
      def process_async(self, document: Document) -> Future[Document]
  ```
- [ ] Cola de procesamiento con prioridades
- [ ] Sistema robusto de manejo de errores

#### 1.2 Mejoras OCR
- [ ] Preprocesamiento de im√°genes
  - Detecci√≥n autom√°tica de orientaci√≥n
  - Correcci√≥n de sesgo
  - Mejora de contraste
- [ ] Detecci√≥n inteligente de layouts
  - Reconocimiento de columnas
  - Identificaci√≥n de tablas
  - Extracci√≥n de headers/footers
- [ ] Soporte multilenguaje
  - Detecci√≥n autom√°tica de idioma
  - Diccionarios espec√≠ficos por dominio

#### 1.3 Optimizaciones LLM
- [ ] Sistema de cach√©
  ```python
  class LlmCache:
      def get_cached_response(self, text_hash: str) -> Optional[str]
      def cache_response(self, text_hash: str, response: str)
  ```
- [ ] Prompts especializados por tipo de documento
- [ ] Sistema de fallback y reintentos

### Sprint 2: API y Almacenamiento

#### 2.1 API REST (FastAPI)
- [ ] Endpoints CRUD
  ```bash
  POST   /api/v1/documents      # Subir documento
  GET    /api/v1/documents      # Listar documentos
  GET    /api/v1/documents/{id} # Obtener documento
  DELETE /api/v1/documents/{id} # Eliminar documento
  ```
- [ ] Autenticaci√≥n y autorizaci√≥n
- [ ] Documentaci√≥n OpenAPI

#### 2.2 Sistema de Almacenamiento
- [ ] Soporte para S3
  ```python
  class S3Storage(StoragePort):
      def save_document(self, doc: Document) -> str
      def load_document(self, path: str) -> Document
  ```
- [ ] Versionado de documentos
- [ ] Gesti√≥n de cach√©

#### 2.3 Monitoreo
- [ ] Logging estructurado
- [ ] M√©tricas de rendimiento
- [ ] Sistema de alertas

### Sprint 3: Testing y CI/CD

#### 3.1 Testing Exhaustivo
- [ ] Tests de integraci√≥n
  ```python
  def test_end_to_end_processing():
      # Probar flujo completo
  
  def test_error_handling():
      # Verificar manejo de errores
  ```
- [ ] Tests de rendimiento
- [ ] Mocks para servicios externos

#### 3.2 Pipeline CI/CD
- [ ] GitHub Actions
  ```yaml
  name: CI/CD Pipeline
  on: [push, pull_request]
  jobs:
    test:
      # Tests automatizados
    lint:
      # An√°lisis de c√≥digo
    deploy:
      # Despliegue autom√°tico
  ```
- [ ] An√°lisis est√°tico
- [ ] Despliegue autom√°tico

#### 3.3 Documentaci√≥n
- [ ] API Reference
- [ ] Gu√≠as de uso
- [ ] Ejemplos pr√°cticos

## M√©tricas de √âxito

1. **Rendimiento**
   - Tiempo de procesamiento < 30s por p√°gina
   - Precisi√≥n OCR > 95%
   - Latencia API < 100ms

2. **Calidad**
   - Cobertura de tests > 80%
   - Zero vulnerabilidades cr√≠ticas
   - Documentaci√≥n actualizada

## Configuraci√≥n del Entorno

```bash
# Instalar dependencias
pip install -e ".[dev]"

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Ejecutar tests
pytest tests/
```

## Configuraci√≥n de Donut OCR

Donut (Document Understanding Transformer) es un modelo de IA avanzado para extracci√≥n de texto y comprensi√≥n de documentos. 

### Par√°metros de Configuraci√≥n

```python
# Configuraci√≥n en .env
MODEL_NAME=naver-clova-ix/donut-base-finetuned-cord-v2  # Modelo pre-entrenado
USE_GPU=false                    # Usar GPU si est√° disponible
PDF_DPI=200                     # Resoluci√≥n de escaneo
MAX_OUTPUT_LENGTH=1024          # Longitud m√°xima de salida
NUM_BEAMS=4                     # N√∫mero de beams para b√∫squeda
NUM_THREADS=4                   # Hilos para procesamiento
TEMPERATURE=0.8                 # Temperatura de generaci√≥n
```

## Contribuci√≥n

1. Fork el repositorio
2. Crea una rama para tu feature
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. Commit tus cambios
   ```bash
   git commit -m "feat(amazing): add something amazing"
   ```
4. Push a la rama
   ```bash
   git push origin feature/amazing-feature
   ```
5. Abre un Pull Request

## Convenciones

- **Commits**: Seguimos [Conventional Commits](https://www.conventionalcommits.org/)
- **C√≥digo**: [Black](https://github.com/psf/black) para formateo
- **Documentaci√≥n**: Docstrings en Google style
- **Testing**: Pytest para todos los tests

## Licencia

Este proyecto est√° licenciado bajo MIT License - ver el archivo [LICENSE](LICENSE) para detalles.

## Agradecimientos

- OpenAI por la API GPT
- Tesseract OCR
- La comunidad de c√≥digo abierto

---

No olvides dar una estrella si encuentras √∫til este proyecto!
